---
title: "Monosomy 7 analysis"
author: "Salvatore Milite"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: references.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Here we analyze data from @1k. Data is publicly available at ![https://www.ebi.ac.uk/gxa/sc/experiments/E-CURD-6/downloads], we just changed the metadata file name to 'metadata.tsv' and the data matrix names to be readable for Seurat. Than the rest of the analysis closely follow the Seurat vignette on pbmc dataset (![https://satijalab.org/seurat/v3.2/pbmc3k_tutorial.html])

```{r }
#Not really sure how the data were analyzed, I think it's worth to repeat it and have the data preproccessed as you want 
library(Seurat) # general scRNA-seq functions
library(biomaRt) # annotations and stuff
# Donwnload the files from the EBI database
# You can call the metadata file as you like
# But remember the actual mtx 10x files shoud have this structure
# directory -> matrix.mtx (with the actual counts, Sparse matrix format), barcodes.tsv (with cellular barcodes) and genes.tsv (with gene names)
meta <-  read.table("metadata.tsv", sep = "\t")
# You give the name of the directory where you have the mtx, barcodes and genes file
data <- Read10X(data.dir = "raw/")
# Convert the identifiers from ENSEMBL to HGNC gene names
ensembl = useMart("ensembl",dataset="hsapiens_gene_ensembl")
res = getBM(attributes=c('ensembl_gene_id','hgnc_symbol'), 
      filters = 'ensembl_gene_id', 
      values = rownames(data), 
      mart = ensembl)
res = res[res$hgnc_symbol != "",,]
data <-  data[res[,1],]
rownames(data) = res[,2]
# Create a seurat object
scdata <- CreateSeuratObject(counts = data, min.cells = 3, min.features = 200 )
```

```{r}
scdata[["percent.mt"]] <- PercentageFeatureSet(scdata, pattern = "^MT-")
VlnPlot(scdata, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)
# Very high quality dataset, with 10x you go with mt.fract > 15/20 and nFeatures > 200-300
#scdata <- subset(scdata, subset = nFeature_RNA > 7500 & nFeature_RNA < 15000 & percent.mt < 15)
scdata <- subset(scdata, subset = nFeature_RNA > 7500 & nFeature_RNA < 15000 & percent.mt < 15 & nCount_RNA > 6.8e+6 & nCount_RNA < 2.4e+7)
```

```{r}
VlnPlot(scdata, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

```


```{r}
scdata <- NormalizeData(scdata)
scdata <- FindVariableFeatures(scdata, selection.method = "vst", nfeatures = 200)
VariableFeaturePlot(scdata)
```

```{r}
scdata <- ScaleData(scdata)
scdata <- RunPCA(scdata, features = VariableFeatures(object = scdata))
DimPlot(scdata, reduction = "pca")
```

```{r}
scdata <- FindNeighbors(scdata, dims = 1:30)
scdata <- FindClusters(scdata, resolution = 0.5)
scdata <- RunUMAP(scdata, dims = 1:30)
new_meta <- as.data.frame(meta$V4)
rownames(new_meta) <-  meta$V1
scdata <- AddMetaData(scdata,new_meta, "patient")
#create a new object with specific patients, for successive analysis,  you can also subset based on the UMAP clusters
DimPlot(scdata, reduction = "umap", group.by = "patient")

scdata_filt <- scdata[,scdata$patient %in% c("patient 1", "H4")]
```

```{r}
FeaturePlot(scdata, features = "PLCB4")
```

As we do not have any prior segmentation nor SNPs VAF we can download a cytobad file from UCSC and try to run CONGAS over entire chromosomes (remember that we are looking for big aneuploidy events).

```{r}
# I load rcongas from source, you can just install the package from github with 
# devtools::install_github("militeee/Rcongas")
library(Rcongas)
library(dplyr)

# Cromosomal arms information
#curl::curl_download("https://hgdownload.soe.ucsc.edu/goldenPath/hg19/database/cytoBand.txt.gz", destfile = "./cytoband.tsv.gz")
# Hope you are on a UNIX system
#system("gzip -d cytoband.tsv.gz")
cyto <-  read.table("cytoband.tsv")

# CONGAS wants a coloumn for prior expectation on the CN value 
cyto <-  cyto %>% dplyr::select(V1, V2, V3, V4) %>%  mutate(V4 = substr(V4, 1,1)) %>%  group_by(V1) %>% summarize(chr = unique(V1), start = min(V2), end = max(V3)) %>% ungroup() %>%  dplyr::select(chr, start, end)%>%  mutate(tot = rep(2, length(chr)))
```

We can retrieve the count matrix from the Seurat object 
```{r}
#extract the different data you want from the seurat object
data_norm <- as.matrix(scdata_filt@assays$RNA@data)
data_mat <- round(as.matrix(scdata_filt@assays$RNA@counts))
```

With dataset having a high number of heterogeneous cellular types, median filtering genes over a chromosome with a short window can be useful to remove effects of cell type specific markers with a lot of count that could potentially create false positive. To do so we define a custom function to be passed to get_data that does this filtering and then sums the counts.

```{r}

filter_median_by_segs <- function(x, k = 3, na.rm = T){
  if(sum(x) == 0) return(0)
  x = runmed(x,k = k, endrule = "constant")
  return(sum(x,na.rm = na.rm))
} 
```

```{r}

express_counts <- Rcongas:::get_data(data_mat, cnv_data = cyto, type = "fixed_binning", fun = filter_median_by_segs, correct_bins = F)
# always take a look at the heatmap 
express_counts <- Rcongas:::filter_segments.rcongas(X = express_counts, filter_mu = 100)

pheatmap::pheatmap(log(apply(express_counts$data$counts, 1, function(x) x/express_counts$data$cnv$mu) %>%  t/ rowSums(express_counts$data$counts)), cluster_cols = F,  show_rownames = F, annotation_row = new_meta, color = RColorBrewer::brewer.pal(9,"Reds"))
# if you feel like scaling, you may also used the scaled genes from the Seurat object as shown above, never tried but more sense than this to me 
#express$data$counts <- scale(express$data$counts, T, T)
```

We are now ready to perform the inference. Note how we are using different theta hyperparameters here compared to the 10x example.
```{r, eval = FALSE}
express_counts$data$counts <-  round(express_counts$data$counts)

res <- Rcongas:::best_cluster(express_counts,model = "MixtureGaussian", clusters = 1:3, steps = 300, lr = 0.01, param_list = list("theta_scale" = 3.5, "theta_rate" =0.01, "cnv_var" = 0.10) , method = "BIC",  MAP = T, posteriors = T, step_post = 150)
# filter small clusters
res_filt <-  Rcongas:::filter_clusters(res, ncells = 10, remove = TRUE)

```
```{r, echo = FALSE}
load("monosomy_res.rda")
res_filt = monosomy_res
de = monosomy_res

```

```{r}
#plotting the results with some annotations

library(RColorBrewer)

bc <-  res_filt$inference$model_selection$best_K

new_meta2 <-  as.data.frame(new_meta)[names(res_filt$inference$models[[bc]]$parameters$assignement),, drop = F]

new_meta2$"Log total counts" <- log10(scdata_filt[,names(res_filt$inference$models[[bc]]$parameters$assignement)]$nCount_RNA)

new_meta2$CONGAS = as.character(res_filt$inference$models[[bc]]$parameters$assignement)

colnames(new_meta2)[1] <- "Sample ID"

p1 = pheatmap::pheatmap(scale(log(apply(apply(express_counts$data$counts[names(res_filt$inference$models[[bc]]$parameters$assignement),], 1, function(x) x/express_counts$data$cnv$mu) %>%  t ,2, function(x) x/ res_filt$inference$models[[bc]]$parameters$norm_factor))[names(sort(res_filt$inference$models[[bc]]$parameters$assignement)),]), cluster_cols = F,  show_rownames = F, annotation_row = new_meta2, color = rev(brewer.pal(11, "RdBu")), cluster_rows = F, gaps_row = cumsum(table(res_filt$inference$models[[bc]]$parameters$assignement)) [c(2,1)],breaks=seq(-3, 3, length.out = 11)
)
p1
```
Than we can again perform DE and plot it.
```{r, eval = FALSE}


de <- calculate_DE(res_filt, round(data_mat)[-which(rownames(data_mat) %in% (Rcongas::hg38_gene_coordinates %>%  filter(chr %in% c("chrX", "chrY")) %>%  pull(gene))),names(res_filt$inference$models[[bc]]$parameters$assignement)], clone1 = "c1", "c2", method = "DESeq2")

```
```{r}
plot_DE_volcano(de)

```

